{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:28:34.414568Z",
     "start_time": "2017-09-15T23:28:34.393029Z"
    }
   },
   "outputs": [],
   "source": [
    "from configs import get_config\n",
    "from data_loader import get_loader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:05:09.231919Z",
     "start_time": "2017-09-15T23:05:09.214349Z"
    }
   },
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:12:21.663902Z",
     "start_time": "2017-09-15T23:12:21.639129Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = get_config(\n",
    "    parse=False,\n",
    "    vocab_size=20000,\n",
    "    hidden_size=300,\n",
    "    n_channel_per_window=2,\n",
    "    label_size=2,\n",
    "    dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:12:23.010191Z",
     "start_time": "2017-09-15T23:12:22.983000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configurations\n",
       "{'batch_size': 100,\n",
       " 'data_dir': PosixPath('/Users/jmin/workspace/fastcampus_chatbot/Day_02/CNN/datasets'),\n",
       " 'dropout': 0.5,\n",
       " 'epochs': 20,\n",
       " 'hidden_size': 300,\n",
       " 'label_size': 2,\n",
       " 'log_every_epoch': 1,\n",
       " 'loss_fn': <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
       " 'lr': 0.001,\n",
       " 'n_channel_per_window': 2,\n",
       " 'optimizer': <class 'torch.optim.sgd.SGD'>,\n",
       " 'save_dir': PosixPath('/Users/jmin/workspace/fastcampus_chatbot/Day_02/CNN/log'),\n",
       " 'save_every_epoch': 1,\n",
       " 'vocab_size': 20000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:04:21.687513Z",
     "start_time": "2017-09-15T23:04:08.559175Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocabulary \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_loader(batch_size=20, max_size=config.vocab_size, is_train=True, data_dir='./datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T00:32:43.844156Z",
     "start_time": "2017-09-16T00:32:43.826688Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = train_loader.dataset.fields['text'].vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T00:37:06.314771Z",
     "start_time": "2017-09-16T00:37:06.295239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi['안']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:05:37.884310Z",
     "start_time": "2017-09-15T23:05:37.862145Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:06:31.807696Z",
     "start_time": "2017-09-15T23:06:31.505804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.batch.Batch at 0x106bf9c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:06:47.227745Z",
     "start_time": "2017-09-15T23:06:47.188252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 10 \n",
       "  1991    503   1196    921    355      0      0     63    176     72     72\n",
       "     5     15    818     28   3288   9169   2541      4     44    215   1658\n",
       "    42   1350    764     26    114    106      1     10    314     10    130\n",
       "   110      1     10    106     66    187      1    604     13    328   1658\n",
       "    39      1    909    189      7      2      1   1051     15    274     95\n",
       "  1482      1    159      4     53    117      1      2    367    166   1658\n",
       "     1      1     16     55    403      1      1    814     10     15    241\n",
       "     1      1     76    123    126      1      1      1    420    414    184\n",
       "     1      1     24     90   5207      1      1      1      1     17    131\n",
       "     1      1    706     50     10      1      1      1      1     38      8\n",
       "     1      1    129     47   5181      1      1      1      1     63    182\n",
       "     1      1     31    304     32      1      1      1      1      4    807\n",
       "     1      1      2   4098   5149      1      1      1      1      3      1\n",
       "     1      1     18   3556    355      1      1      1      1    130      1\n",
       "     1      1   2677    307      2      1      1      1      1     25      1\n",
       "     1      1   1065      2    128      1      1      1      1     14      1\n",
       "     1      1     54    106    722      1      1      1      1      3      1\n",
       "     1      1    473      8      3      1      1      1      1     49      1\n",
       "     1      1   2079     12    673      1      1      1      1    117      1\n",
       "     1      1      5    391   2145      1      1      1      1   1022      1\n",
       "     1      1   6483     49      6      1      1      1      1     15      1\n",
       "     1      1      9   1941   6878      1      1      1      1    414      1\n",
       "     1      1      4      7     12      1      1      1      1     17      1\n",
       "     1      1    134     53     20      1      1      1      1    162      1\n",
       "     1      1    422   1555     64      1      1      1      1      1      1\n",
       "     1      1      9     97    174      1      1      1      1      1      1\n",
       "     1      1    186    107     10      1      1      1      1      1      1\n",
       "     1      1     11     15   3111      1      1      1      1      1      1\n",
       "     1      1   1046    244     12      1      1      1      1      1      1\n",
       "     1      1   1196      1    728      1      1      1      1      1      1\n",
       "     1      1   1067      1  18218      1      1      1      1      1      1\n",
       "     1      1      9      1    171      1      1      1      1      1      1\n",
       "     1      1    270      1    704      1      1      1      1      1      1\n",
       "     1      1   2037      1     25      1      1      1      1      1      1\n",
       "     1      1   6490      1     12      1      1      1      1      1      1\n",
       "     1      1  16758      1   3111      1      1      1      1      1      1\n",
       "     1      1    258      1     34      1      1      1      1      1      1\n",
       "     1      1      9      1  14521      1      1      1      1      1      1\n",
       "     1      1   1308      1     99      1      1      1      1      1      1\n",
       "     1      1     54      1     63      1      1      1      1      1      1\n",
       "     1      1    368      1     49      1      1      1      1      1      1\n",
       "     1      1   1386      1    187      1      1      1      1      1      1\n",
       "     1      1     13      1     30      1      1      1      1      1      1\n",
       "     1      1   3787      1     22      1      1      1      1      1      1\n",
       "     1      1      1      1     38      1      1      1      1      1      1\n",
       "     1      1      1      1    124      1      1      1      1      1      1\n",
       "\n",
       "Columns 11 to 19 \n",
       "    57    619     83   1568   1531  16929    100   5612   2909\n",
       "   199    174      2   2582    314   1557    919   1557     15\n",
       "   334     10      5      3      7    226      4   1877    852\n",
       "     5      0    106   1396     45    165    134    133     11\n",
       "   154      1      8     25      8     22   1123      1   3859\n",
       "  2541      1    121    405    187   4481   1461      1    198\n",
       "     1      1      2     53     12   1126      2      1      1\n",
       "     1      1    447     22    711    557     53      1      1\n",
       "     1      1    281    783     26    242     25      1      1\n",
       "     1      1      1     13    383     39    876      1      1\n",
       "     1      1      1    169   1759     59      1      1      1\n",
       "     1      1      1      1    738   7096      1      1      1\n",
       "     1      1      1      1   1726      1      1      1      1\n",
       "     1      1      1      1     91      1      1      1      1\n",
       "     1      1      1      1     25      1      1      1      1\n",
       "     1      1      1      1     15      1      1      1      1\n",
       "     1      1      1      1  12112      1      1      1      1\n",
       "     1      1      1      1    350      1      1      1      1\n",
       "     1      1      1      1     11      1      1      1      1\n",
       "     1      1      1      1     20      1      1      1      1\n",
       "     1      1      1      1     24      1      1      1      1\n",
       "     1      1      1      1      5      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "     1      1      1      1      1      1      1      1      1\n",
       "[torch.LongTensor of size 46x20]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [max_seq_len, batch_size]\n",
    "batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:26:26.059147Z",
     "start_time": "2017-09-15T23:26:26.040908Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.LongTensor of size 20]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch_size]\n",
    "batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cnn_text_classification.png\", width=600, height=60>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:23:17.286946Z",
     "start_time": "2017-09-15T23:23:17.138573Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNN, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        \n",
    "        self.conv = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(3, config.hidden_size)),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(4, config.hidden_size)),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(5, config.hidden_size))\n",
    "        ])\n",
    "        \n",
    "        n_total_channels = len(self.conv) * config.n_channel_per_window\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(n_total_channels, config.label_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, max_seq_len]\n",
    "        Return:\n",
    "            logit: [batch_size, label_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        # [batch_size, max_seq_len, hidden_size]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # [batch_size, 1, max_seq_len, hidden_size]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Apply Convolution filter followed by Max-pool\n",
    "        out_list = []\n",
    "        for conv in self.conv:\n",
    "            \n",
    "            ########## Convolution #########\n",
    "            \n",
    "            # [batch_size, n_kernels, _, 1]\n",
    "            x_ = F.relu(conv(x))\n",
    "            \n",
    "            # [batch_size, n_kernels, _]\n",
    "            x_ = x_.squeeze(3)\n",
    "            \n",
    "            ########## Max-pool #########\n",
    "            \n",
    "            # [batch_size, n_kernels, 1]\n",
    "            x_ = F.max_pool1d(x_, x_.size(2))\n",
    "            \n",
    "            # [batch_size, n_kernels]\n",
    "            x_ = x_.squeeze(2)\n",
    "            \n",
    "            out_list.append(x_)\n",
    "        \n",
    "        # [batch_size, 3 x n_kernels]\n",
    "        out = torch.cat(out_list, 1)\n",
    "        \n",
    "        ######## Dropout ########\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # [batch_size, label_size]\n",
    "        logit = self.fc(out)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:23:17.975385Z",
     "start_time": "2017-09-15T23:23:17.753946Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:23:18.260641Z",
     "start_time": "2017-09-15T23:23:18.238268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN (\n",
       "  (embedding): Embedding(20000, 300)\n",
       "  (conv): ModuleList (\n",
       "    (0): Conv2d(1, 2, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 2, kernel_size=(4, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 2, kernel_size=(5, 300), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout (p = 0.5)\n",
       "  (fc): Linear (6 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:32:12.728627Z",
     "start_time": "2017-09-15T23:32:12.710212Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = config.loss_fn()\n",
    "\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:33:07.947242Z",
     "start_time": "2017-09-15T23:33:07.930075Z"
    }
   },
   "source": [
    "# Build Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:33:06.342475Z",
     "start_time": "2017-09-15T23:33:06.321496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.sgd.SGD at 0x11458ad30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = config.optimizer(model.parameters(), config.lr)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:39:04.494254Z",
     "start_time": "2017-09-15T23:37:41.750748Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/7302 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1/7302 [00:00<46:27,  2.62it/s]\u001b[A\n",
      "  0%|          | 3/7302 [00:00<35:12,  3.46it/s]\u001b[A\n",
      "  0%|          | 5/7302 [00:00<28:13,  4.31it/s]\u001b[A\n",
      "  0%|          | 7/7302 [00:00<23:11,  5.24it/s]\u001b[A\n",
      "  0%|          | 8/7302 [00:01<21:16,  5.72it/s]\u001b[A\n",
      "  0%|          | 9/7302 [00:01<18:53,  6.44it/s]\u001b[A\n",
      "  0%|          | 11/7302 [00:01<16:21,  7.43it/s]\u001b[A\n",
      "  0%|          | 12/7302 [00:01<15:33,  7.81it/s]\u001b[A\n",
      "  0%|          | 14/7302 [00:01<14:03,  8.64it/s]\u001b[A\n",
      "  0%|          | 16/7302 [00:01<13:04,  9.28it/s]\u001b[A\n",
      "  0%|          | 18/7302 [00:01<12:36,  9.63it/s]\u001b[A\n",
      "  0%|          | 20/7302 [00:02<12:39,  9.59it/s]\u001b[A\n",
      "  0%|          | 22/7302 [00:02<12:19,  9.84it/s]\u001b[A\n",
      "  0%|          | 24/7302 [00:02<12:53,  9.41it/s]\u001b[A\n",
      "  1%|          | 52/7302 [00:05<11:02, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 20.5067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 101/7302 [00:09<12:42,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 151/7302 [00:14<09:37, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6825\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 201/7302 [00:19<11:25, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.8007\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 250/7302 [00:24<11:38, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6258\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 301/7302 [00:29<12:12,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6719\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 351/7302 [00:34<14:44,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6882\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 401/7302 [00:40<12:21,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6841\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 451/7302 [00:46<13:30,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7267\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 501/7302 [00:51<12:24,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7666\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 551/7302 [00:55<10:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 601/7302 [01:00<09:57, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 651/7302 [01:05<09:58, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 2.6338\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 701/7302 [01:09<09:45, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6943\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 753/7302 [01:14<08:23, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6882\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 801/7302 [01:19<10:18, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 839/7302 [01:22<12:51,  8.38it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a30c1ac84de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# [batch_size, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-9ce04d6a079a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# [batch_size, n_kernels, _, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# [batch_size, n_kernels, _]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # n_epochs\n",
    "    print(f'Epoch: {epoch}')\n",
    "    for batch_i, batch in enumerate(tqdm(train_loader)):\n",
    "        # text: [max_seq_len, batch_size]\n",
    "        # label: [batch_size]\n",
    "        text, label = batch.text, batch.label\n",
    "\n",
    "        # [batch_size, max_seq_len]\n",
    "        text.data.t_()\n",
    "        \n",
    "        # [batch_size, 2]\n",
    "        logit = model(text)\n",
    "        \n",
    "        # Calculate loss\n",
    "        batch_loss = loss_fn(logit, label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_i + 1) % 50 == 0:\n",
    "            tqdm.write(f'batch loss: {batch_loss.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mldemo]",
   "language": "python",
   "name": "conda-env-mldemo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
